---
title: "Causes of Varying Death Rates in the U.S."
subtitle: "W203 Lab 2"
author: "Jenny Conde, Spencer Hong, Kevin Lu, Spencer Song"
output: pdf_document
---

<!-- TODO: JENNY DELETE ALL SKSKSKSKs (and comments) -->

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(car)
library(lmtest)
library(sandwich)
library(stargazer)
library(tidyverse)
library(magrittr)
library(ggplot2)
library(dplyr)
library(patchwork)
library(olsrr)
library(magick)
library(knitr)
library(ggcorrplot)
```

# Introduction

<!-- Your introduction should present a research question and explain the concept that you're attempting to measure and how it will be operationalized. This section should pave the way for the body of the report, preparing the reader to understand why the models are constructed the way that they are. It is not enough to simply say "We are looking for policies that help against COVID."  Your introduction must do work for you, focusing the reader on a specific measurement goal, making them care about it, and propelling the narrative forward. This is also good time to put your work into context, discuss cross-cutting issues, and assess the overall appropriateness of the data.

(From Rubric) Is the introduction clear? Is the research question specific and well defined? Does the introduction motivate a specific concept to be measured and explain how it will be operationalized. Does it do a good job of preparing the reader to understand the model specifications?

TODO: jenny conde
Driving question: What causes higher death rates in some states versus others?
  What factors impact ___
Variable categories: Health, policy, socioeconomic, other -->

## Background and Overview

The COVID-19 pandemic has overturned nearly all aspects of normal life over the past year. The U.S. has particularly suffered, with 550,000 COVID-19 deaths, more than any other nation in the world [(NY Times)](https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html). However, not all areas of the U.S. have been equally affected. While some states have seen relatively few cases and deaths, others have been significantly impacted, seeing overwhelmed healthcare systems and lockdowns. This motivates our primary research question: What causes higher fatality rates from COVID-19 in some states versus others? What are the primary factors driving higher fatality rates across states?

To answer this question, we analyze the cumulative COVID-19 fatality rate from January 22, 2020 through March 31, 2021. We calculate the fatality rate as the number of deaths per positive cases. We operationalize several categories of factors that likely have a causal relationship with fatality rate based on our research from media articles, publications, and government sources. These categories include pre-existing health conditions, enacted policy, and socioeconomic characteristics. We additionally include number of ICU beds per 10,000 people to represent the capacity of healthcare systems in each state.

With this background knowledge about factors making people more prone to catching a severe case of COVID-19, we can perform a causal analysis using the one-equation structural model to determine how prevalent these factors are at a state-level. Our causal analysis consists of three models. Our first model contains the variables we believe have the largest causal impact on death rate. Our second model builds on this to include more of our dataset, and finally, our third model includes all data we collected.

## Data Collection and Cleaning

<!-- TODO: spencer song

- explain how we define "death rate" (i.e. deaths/cases)--why is this operationalization more relevant than alternatives (ex. deaths per capita) -- Jenny explains this in the intro a bit but this operationalization probably merits further explanation-->

Our operationalized pre-existing health conditions were largely informed by the Center for Disease Control's list of medical conditions that make adults more likely to get severely ill from COVID-19 [(CDC)](https://www.cdc.gov/coronavirus/2019-ncov/need-extra-precautions/people-with-medical-conditions.html). We focused our policy data on mask requirements and stay at home orders. Individuals' socioeconomic status has also been known to make them more vulnerable to COVID-19, so we include features like unemployment, income, and crowding [(McKinsey)](https://www.mckinsey.com/featured-insights/coronavirus-leading-through-the-crisis/charting-the-path-to-the-next-normal/socioeconomic-vulnerability-increases-the-risk-of-dying-from-covid-19#:~:text=Socioeconomic%20vulnerability%20increases%20the%20risk%20of%20dying%20from%20COVID%2D19,-COVID%2D19%20Inequality&text=September%2010%2C%202020%20People%20who,coronavirus%20than%20the%20general%20population.). Finally, public officials have stressed ICU capacity as an important factor in handling large numbers of severe COVID-19 cases, so we include the number of ICU beds per 10,000 people as an additional feature.

Much of this data was collected from a variety of sources, but we were able to join on State FIPS (Federal Information Processing System) Codes. Our data was primarily on a county level, so we aggregated our data to a state level and converted the data to percentage rates to use for our regression. We chose to collect data on a county level because more granular data is likely more precise. Additionally, this opens the opportunity for future analysis at a county level. We made the choice to define "Fatality_Rate" as the total number of deaths divided by total number of cases for each state from January 22, 2020 through March 31, 2021. This normalization allows us to focus on why people are dying from COVID-19 at higher rates rather than how COVID-19 spreads in states.

We also made the choice to omit Hawaii, Alaska, and District of Columbia from our states, as we found that these states were outliers in our socioeconomic analysis and policy factors. District of Columbia is primarily urban, so the demographics, multi-unit housing percentages, and crowding were all drastically different from the rest of our data points, causing nonlinearity with our regressions due to our small dataset. Similarly, Hawaii and Alaska are not a part of the contiguous United States, so their COVID-19 management was much more travel/flight dependent, whereas the rest of the United States was openly exposed to travel. Because these two states are isolated from the rest of the US, they can more effectively regulate travel into and out of the state. Finally, Hawaii and Alaska have significantly different demographic characteristics--a high number of minorities and low population density, respectively. These states had many different factors that would impact the fatality of their COVID-19 cases, so for the purpose of our question, we are bounding our dataset to the lower 48 states.

<!-- DO NOT DELETE Alaska: low density "it does not function like a normal state sksksk" - Kevin Lu, Public Official with hydroflasksksk -->
<!--ToDo: LIST OUT VARIABLE GROUPINGS and sources @SPENCER SONG  -->

These are the variables we have collected and considered prior to performing exploratory data analysis.

1. \textbf{Response Variable}
\vspace{-5pt}

> Fatality Rate [(USA Facts)](https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/): calculated as the ratio of cumulative deaths to cumulative cases

2. \textbf{Health Variables}
\vspace{-5pt}

> 1. % Adults with Diabetes [(CDC)](https://gis.cdc.gov/grasp/diabetes/DiabetesAtlas.html#)
\vspace{-5pt}

> 2. % Deaths from Stroke [(CDC)](https://nccd.cdc.gov/DHDSPAtlas/?state=County)
\vspace{-5pt}

> 3. % Deaths from Heart Disease [(CDC)](https://nccd.cdc.gov/DHDSPAtlas/?state=County)
\vspace{-5pt}

> 4. % Adults who Smoke [(CHR)](https://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation)
\vspace{-5pt}

> 5. % Deaths from Chronic Respiratory Disease [(GHDx)](http://ghdx.healthdata.org/record/ihme-data/united-states-chronic-respiratory-disease-mortality-rates-county-1980-2014)
\vspace{-5pt}

> 6. % Deaths from Asthma [(GHDx)](http://ghdx.healthdata.org/record/ihme-data/united-states-chronic-respiratory-disease-mortality-rates-county-1980-2014)
\vspace{-5pt}

> 7. % Adults with Obesity [(CHR)](https://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation)

3. \textbf{Policy Variables}
\vspace{-5pt}

> 1. Mask Ratio [(W203)](https://docs.google.com/spreadsheets/d/1zu9qEWI8PsOI_i8nI_S29HDGHlIp2lfVMsGxpQ5tvAQ/edit#gid=1348247662): calculated as the proportion of days each state had a mask mandate between April 8, 2020, and April 4, 2021
\vspace{-5pt}

> 2. Stay at Home Ratio [(W203)](https://docs.google.com/spreadsheets/d/1zu9qEWI8PsOI_i8nI_S29HDGHlIp2lfVMsGxpQ5tvAQ/edit#gid=1348247662): calculated as the proportion of days each state had a stay at home mandate between March 19, 2020, and January 25, 2021

4. \textbf{Socioeconomic Variables}
\vspace{-5pt}

> 1. % Unemployed [(CDC)](https://www.atsdr.cdc.gov/placeandhealth/svi/data_documentation_download.html)
\vspace{-5pt}

> 2. % Minority [(CDC)](https://www.atsdr.cdc.gov/placeandhealth/svi/data_documentation_download.html)
\vspace{-5pt}

> 3. % Crowding [(CDC)](https://www.atsdr.cdc.gov/placeandhealth/svi/data_documentation_download.html)
\vspace{-5pt}

> 4. % Adults Living in Multi-Unit Dwellings [(CDC)](https://www.atsdr.cdc.gov/placeandhealth/svi/data_documentation_download.html)
\vspace{-5pt}

> 5. % Adults Living in Poverty [(CDC)](https://www.atsdr.cdc.gov/placeandhealth/svi/data_documentation_download.html)
\vspace{-5pt}

> 6. Median Household Income [(World Population Review)](https://worldpopulationreview.com/state-rankings/median-household-income-by-state)
\vspace{-5pt}

> 7. % Adults Over Age 65 [(CHR)](https://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation)
\vspace{-5pt}

5. \textbf{Miscellaneous Variables}
\vspace{-5pt}

> 1. ICU Beds per 10,000 people [(KFF)](https://www.kff.org/other/state-indicator/icu-beds/?currentTimeframe=0&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D)

# Model Building Process

<!--You will next build a set of models to investigate your research question, documenting your decisions. Here are some things to keep in mind during your model building process:

1. *What do you want to measure*? Make sure you identify one key variable (possibly more in rare cases) that will allow you to derive conclusions relevant to your research question, and include this variables in all model specifications.

2. Is your modeling goal one of description or explanation?-

3. What [covariates](https://en.wikipedia.org/wiki/Dependent_and_independent_variables#Statistics_synonyms) help you achieve your modeling goals? What covariates are problematic, either due to *collinearity*, or because they will absorb some of a causal effect you want to measure?

4. What *transformations*, if any, should you apply to each variable? These transformations might reveal linearities in the data, make your results relevant, or help you meet model assumptions.

5. Are your choices supported by exploratory data analysis (*EDA*)? You will likely start with some general EDA to *detect anomalies* (missing values, top-coded variables, etc.). From then on, your EDA should be interspersed with your model building. Use visual tools to *guide* your decisions. You can also leverage statistical *tests* to help assess whether variables, or groups of variables, are improving model fit.
  - remove mask policy?-->

<!-- 1. What do you want to measure?
The team identified fatality rates as the key variable to be measured as we look to understand the relationship between fatality rates and several chosen variables that fall within the health, policy, or socioeconomic realms. Fatality rates are calculated as CHECK THIS!!!!! number of deaths / number of cases in a state over the entire course of our dataset. -->

## Measurement/Response Variable

The team identified fatality rates as the key variable to be measured as we look to understand the relationship between fatality rates and several chosen variables that fall within the health, policy, or socioeconomic categories.

## An Explanatory Analsis
Our model is an explanatory one, as we not only describe the COVID-19 data and trends but also provide causal relationships between each chosen independent and dependent variables. We plan on explaining causes in the changes in fatality rates.

<!-- 3. What [covariates](https://en.wikipedia.org/wiki/Dependent_and_independent_variables#Statistics_synonyms) help you achieve your modeling goals? What covariates are problematic, either due to *collinearity*, or because they will absorb some of a causal effect you want to measure? -->

## Covariate Descriptions

\textbf{Health}: We selected seven different health covariates as listed out above. These variables were chosen because the CDC has claimed that adults with these conditions are more likely to suffer from severe cases of COVID-19 [(CDC)](https://www.cdc.gov/coronavirus/2019-ncov/need-extra-precautions/people-with-medical-conditions.html). However, a few causal relationships exist among these health variables. For example, obesity is a known cause of diabetes, and smoking is known to cause asthma. We additionally found high correlations between these variables. Because of this, we will limit our use of health variables in our models and ensure that no causal relationships exist between remaining variables.

\textbf{Policy}: The covariates for both mask mandate and stay-at-home policy durations are of concern as they both show a positive linear relationship with fatality rates.

\textbf{Socioeconomic}:

\textbf{Miscellaneous}: The covariates for senior percentages and ICU beds per 10000 actually appear to be of little concern. Neither seem to be overly problematic due to collinearity. 

## Covariate Transformations

<!-- 4. What *transformations*, if any, should you apply to each variable? These transformations might reveal linearities in the data, make your results relevant, or help you meet model assumptions. -->

When performing EDA on our features, we plotted and analyzed scatterplots of fatality rate versus each explanatory variable. We assessed how transformations could make the relationships between our explanatory and response variables more linear and tried various combinations of logarithmic and polynomial transformations. Based on our analysis, we decided to apply no transformation to fatality rate, our response variable, and the subsections below outline the transformations made to the variables within each subset.

\textbf{Health}: For health variables, we observed that transformations did not improve the linear relationships between our explanatory variables and fatality rate. Therefore, no transformations were appropriate for any of the health variables. Overall, our diabetes, heart disease, and smoker features had positive correlations with fatality rate. Chronic respiratory disease and asthma both had negative correlations, which seemed counterintuitive, and obesity and stroke essentially had zero correlation.

\textbf{Policy}: For policy variables, no logarithmic or polynomial transformation conducted improved linear relationships between our explanatory variables (duration of each state's mask mandate & stay-at-home policies) and fatality rate.

\textbf{Socioeconomic}:

\textbf{Miscellaneous}: ICU Beds per 10000 should be used with a log transformation, while senior percentage should not take any transformations. With ICU Beds per 10000, we found that there is a lot of change in the lower ICU Bed values, so the covariate becomes more linear and evenly distributed with a log transformation.


<!--5. Are your choices supported by exploratory data analysis (*EDA*)? You will likely start with some general EDA to *detect anomalies* (missing values, top-coded variables, etc.). From then on, your EDA should be interspersed with your model building. Use visual tools to *guide* your decisions. You can also leverage statistical *tests* to help assess whether variables, or groups of variables, are improving model fit.
  - remove mask policy?-->
  
5. Are your choices supported by exploratory data analysis (*EDA*)?

TODO: EDA for all 3 model types and reasoning for specific applied transformations
  - remove NA and check for reasoning with why they existed (make sure not all from one state, etc.)
  - scatter, hists, bar?, box 
  - variable summary, outlier removal? / reasoning
  - transformation logic (transformations to use,etc. include reasoning)
  
TODO: 
  - show minority percentage scatterplots: normal vs logged --> Kevin
  - show scatterplots of Fatality_Rate vs everything else --> Spencer Hong
  - show correlation of "before and after" --> Jenny
  - boxplot to show outliers --> Spencer Song

```{r, echo=FALSE, warning = FALSE, message = FALSE, fig.cap="Scatterplots for each explanatory variable vs Fatality Rate", fig.pos='!h', out.extra='trim={0 1cm 0 1cm},clip', fig.align="center"}
df_figs <- read_csv('FinalDF_nicecols.csv')
df_figs <- df_figs[-c(2, 9, 12), ] # remove Alaska, Hawaii, D.C.

#pairs(df_figs[,6:10], pch = 19, lower.panel = NULL)

# Scatter plots per explanatory variable
mask_scatter <- ggplot(df_figs, aes(x = `Mask Ratio`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
home_scatter <- ggplot(df_figs, aes(x = `Home Ratio`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
diabetes_scatter <- ggplot(df_figs, aes(x = `% Adults with Diabetes`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
asthma_scatter <- ggplot(df_figs, aes(x = `% Deaths from Asthma`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
obesity_scatter <- ggplot(df_figs, aes(x = `% Adults with Obesity`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
stroke_scatter <- ggplot(df_figs, aes(x = `% Deaths from Stroke`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
heart_scatter <- ggplot(df_figs, aes(x = `% Deaths from Heart Disease`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
smoke_scatter <- ggplot(df_figs, aes(x = `% Adults who Smoke`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
respiratory_scatter <- ggplot(df_figs, aes(x = `% Deaths from Chronic
Resp Disease`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
unemployed_scatter <- ggplot(df_figs, aes(x = `% Unemployed`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
minority_scatter <- ggplot(df_figs, aes(x = `% Minority`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
crowding_scatter <- ggplot(df_figs, aes(x = `% Crowding`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
multiunit_scatter <- ggplot(df_figs, aes(x = `% Adults in Multi-
Unit Dwellings`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
poverty_scatter <- ggplot(df_figs, aes(x = `% Adults in Poverty`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
elders_scatter <- ggplot(df_figs, aes(x = `% Adults >65`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
icubeds_scatter <- ggplot(df_figs, aes(x = `ICUBeds`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
icubedsper_scatter <- ggplot(df_figs, aes(x = `ICU Beds Per 10,000`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)
income_scatter <- ggplot(df_figs, aes(x = `Household Income`, y = `Fatality Rate`))+ 
  geom_point(size=2.5)

test_scatter <- (mask_scatter | home_scatter)

test_scatter

test_scatter <- (diabetes_scatter | asthma_scatter)

test_scatter

test_scatter <- (obesity_scatter | stroke_scatter)

test_scatter

test_scatter <- (heart_scatter |  smoke_scatter)

test_scatter

test_scatter <- (respiratory_scatter | unemployed_scatter)

test_scatter

test_scatter <- (minority_scatter | crowding_scatter)

test_scatter

test_scatter <- (multiunit_scatter | poverty_scatter)

test_scatter

test_scatter <- (elders_scatter | income_scatter)

test_scatter

test_scatter <- (icubeds_scatter | icubedsper_scatter)

test_scatter
```
  

```{r, echo=FALSE, warning = FALSE, message = FALSE, fig.cap="Changes in correlations between explanatory variables before (left) and after (right) removing some features in Model 2.", fig.pos='!h', out.extra='', fig.align="center"}

vars_2_reduced <- subset(df_figs, select = c('Mask Ratio', "% Adults with Diabetes", '% Unemployed', 'Home Ratio', '% Deaths from Chronic
Resp Disease', '% Minority'))

vars_2_orig <- subset(df_figs, select = c('% Deaths from Heart Disease', '% Adults in Poverty', 'Mask Ratio', "% Adults with Diabetes", '% Unemployed', 'Home Ratio', '% Minority', '% Deaths from Chronic
Resp Disease'))

res_2_orig <- cor(vars_2_orig)
model_2_plot1 <- ggcorrplot(res_2_orig, type = "upper", method = "square", tl.cex = 8, tl.srt = 90, hc.order = FALSE, colors = c("#6D9EC1", "white", "#E46726"), show.legend = FALSE) 

res_2_reduced <- cor(vars_2_reduced)
model_2_plot2 <- ggcorrplot(res_2_reduced, type = "upper", method = "square", tl.cex = 8, tl.srt = 90, show.legend = FALSE, colors = c("#6D9EC1", "white", "#E46726"))

model_2_combined_plot <- (model_2_plot1 | model_2_plot2) + theme(legend.position='bottom')

model_2_combined_plot
```

```{r, echo=FALSE, warning = FALSE, message = FALSE, fig.cap='Changes in correlations between explanatory variables before (left) and after (right) removing some features in Model 3.', fig.pos='!h', out.extra='', fig.align="center"}

vars_3_orig <- subset(df_figs, select = -c(`State`, `Deaths`, `Cases`, `Population`, `Population..20..`, `Population >65`, `ICUBeds`, `Fatality Rate`, `% Adults in Poverty`, `% Deaths from Heart Disease`))

vars_3_reduced <- subset(df_figs, select = -c(`State`, `Deaths`, `Cases`, `Population`, `Population..20..`, `Population >65`, `ICUBeds`, `Fatality Rate`, `% Adults in Poverty`, `% Deaths from Heart Disease`, `Household Income`, `% Adults who Smoke`, `% Adults with Obesity`))

res_3_orig <- cor(vars_3_orig)
model_3_plot1 <- ggcorrplot(res_3_orig, type = "upper", method = "square", tl.cex = 6, tl.srt = 90, hc.order = FALSE, colors = c("#6D9EC1", "white", "#E46726"), show.legend = FALSE) 

res_3_reduced <- cor(vars_3_reduced)
model_3_plot2 <- ggcorrplot(res_3_reduced, type = "upper", method = "square", tl.cex = 6, tl.srt = 90, show.legend = FALSE, colors = c("#6D9EC1", "white", "#E46726"))

model_3_combined_plot <- (model_3_plot1 | model_3_plot2) + theme(legend.position='bottom')

model_3_combined_plot
```

<!-- At the same time, it is important to remember that you are not trying to create one perfect model. You will create several specifications, giving the reader a sense of how robust (or sensitive) your results are to modeling choices, and to show that you're not just cherry-picking the specification that leads to the largest effects. -->

<!-- At a minimum, you should include the following three specifications:

1. **Limited Model**: A model that includes *only the key variable* you want to measure and nothing (or almost nothing) else. This variables might be transformed, as determined by your EDA, but the model should include the absolute minimum number of covariates (perhaps one, or at most two-three, covariates if they are so crucial that it would be unreasonable to omit them). 
1. **Model Two**: A model that includes *key explanatory variables and covariates that you believe advance your modeling* goals without introducing too much multicollinearity or causing other issues. This model should strike a balance between accuracy and parsimony and reflect your best understanding of the relationships among key variables.
1. **Model Three**: A model that includes the *previous covariates, and many other covariates*, erring on the side of inclusion. A key purpose of this model is to evaluate how parameters of interest change (if at all) when additional, potentially colinear variables are included in the model specification.-->
  
```{r, echo = FALSE, message = FALSE, warning = FALSE}
df <- read_csv('FinalDF.csv')
df <- df[-c(2, 9, 12), ] # remove Alaska, Hawaii, D.C.
```

## Limited Model 
$\text{Fatality Rate} = \beta_0 + \beta_1 \text{ Mask Policy} + \beta_2 \text{ % Adults with Diabetes} + \beta_3 \text{ % Unemployment} + u$

Of all the variables we considered, we chose to include the duration a mask mandate policy was in place, the % of adults diagnosed with diabetes, and the percent unemployment for each state. We chose one variable from each specific topic as to provide an encompassing view of possible causes for the change in fatality rates. These three were determined to be the most crucial from all the explanatory variables. For mask mandate, public health officials consistently stressed the efficacy to reduce transmission of COVID-19, which would reduce the number of fatalities. For percent adults with diabetes, we made the assumption that it encompasses several other health conditions as people with diabetes can tend to have additional underlying health conditions. Therefore, we wanted to include this variable as it would provide an overarching health explanatory variable. For percent unemployment, individuals without a job would have no or inadequate health care, which could lead them to having less accessibility and opportunities to receive medical treatments. During the pandemic, research shows that low-income areas have been severly impacted by COVID-19, which led to us choosing percent unemployment as the socioeconomic explanatory variable for the limited model.

```{r}
model_limited <- lm(Fatality_Rate ~ mask_ratio + Diabetes_Diagnosed_Perc + Unemployment_Perc, data = df)
#coeftest(model_limited)
#ols_vif_tol(model_limited)
#plot(density(resid(model_limited)))
#qqnorm(resid(model_limited))
#qqline(resid(model_limited))
```

After running the coefficient test, we observe that both mask duration and unemployment percentage are both statistically significant at a 95% significance level or greater. However, mask duration has a positive impact on predicted fatality rates, which goes against our assumption that states that implemented mask mandates longer would observe a decrease in predicted fatality rates. Except, the model calculates, holding everything equal, with a one percent increase in the duration of a mask mandate, we would expect 0.003 percent increase in predicted fatality rates. For unemployment percentage, the model shows with a one percent increase in poverty, we would expect a 0.19 percent increase in predicted fatality rate.

The VIF values for all three independent variables are all less than two, which indicates that there is minimal multicollinearity among them. With that said, the tolerance, or percent of variance in each variable that cannot be accounted for by the other predictors, of each variable is greater than 0.60. This suggests that there are variables not in the model that account for those predictors. Given this information, we will construct a second model that includes a few more explanatory variables in order to lower the tolerance values. Then, Model Two will be compared to the Limited Model to determine which model provides a better fit for predicted values. The variables to be added are the duration of stay-at-home policies, percentage of deaths from chronic respiratory diseases, and the log-transformation of minority percentage of each state.

## Model Two
$\text{Fatality Rate} = \beta_0 + \beta_1 \text{ Mask Policy} + \beta_2 \text{ % Adults with Diabetes} + \beta_3 \text{ % Unemployment} + \beta_4 \text{ Home Policy} + \beta_5 \text{ % Chronic Resp Deaths} + \beta_6 \text{ log(% Minority)} + u$

```{r}
model_two <- lm(Fatality_Rate ~ mask_ratio + Diabetes_Diagnosed_Perc + Unemployment_Perc + home_ratio + Chronic_Respiratory_Disease_Death_Perc + log(Minority_Percentage), data = df)
#coeftest(model_two)
#ols_vif_tol(model_two)
#plot(density(resid(model_two)))
#qqnorm(resid(model_two))
#qqline(resid(model_two))

#print(anova(model_limited, model_two))
```

With the additional variables, Model Two has three statistically significant explanatory variables at a 90% or greater level of significance - percent of adults diagnosed with diabetes, percent unemployment, and percent of deaths from chronic respiratory disease. Also, we observe that the mask mandate policy variable is no longer statistically significant. Both percent of adults diagnosed with diabetes and unemployment percentage have a positive effect on fatality rates while the percent of chronic respiratory deaths has negative effect, which is concerning as we would expect to have an increased effect on fatality rates as percent of chronic respiratory deaths increases.

The VIF values for all six independent variables are all less than four, which indicates that there is minimal multicollinearity among them. In addition, the tolerance levels of each variable were lower than the Limited Model indicating that the added variables accounted for more for one another than the previous model. The Anova test we ran to compare the fits of the Limited Model and Model Two calculates a p-value less than a 0.05 level of significance level. This shows that by adding the new nine variables leads to a more significant improvement of predicted fatality rates compared to the Limited Model. We will proceed to constructing a third model that will add six other explanatory variables to include: percent of adults living in multi-unit dwellings, percent of crowding, percent of asthma deaths, ICU beds per 10,000, percent of stroke deaths, and percent of adults over the age of 65. Model Three will similarly be examined if it is a better fit than Model Two as currently Model Two is our preferred model.

## Model Three
$\text{Fatality Rate} = \beta_0 + \beta_1 \text{ Mask Policy} + \beta_2 \text{ % Adults with Diabetes} + \beta_3 \text{ % Unemployment} + \beta_4 \text{ Home Policy} + \beta_5 \text{ % Chronic Resp Deaths} + \beta_6 \text{ log(% Minority)} + \beta_7 \text{ % Multi-Unit Dwelling)} + \beta_8 \text{ % Crowding} + \beta_9 \text{ % Asthma Deaths} + \beta_10 \text{ % ICUBedsPer10K} + \beta_11 \text{ % Stroke Deaths} + \beta_12 \text{ % Adults >65} + u$

```{r}
model_three <- lm(Fatality_Rate ~ Multi_Unit_Perc + Unemployment_Perc + home_ratio + log(Minority_Percentage) + Crowding_Perc + Asthma_Deaths_Perc + Chronic_Respiratory_Disease_Death_Perc + ICUBedsPer10000 + Diabetes_Diagnosed_Perc + Stroke_Death_Perc + mask_ratio + Senior_Perc, data = df)

#coeftest(model_three)
#ols_vif_tol(model_three)
#plot(density(resid(model_three)))
#qqnorm(resid(model_three))
#qqline(resid(model_three))

#print(anova(model_two, model_three))
```

With the additional variables, Model Three has three statistically significant explanatory variables at a 95% or greater level of significance - unemployment percentage, percent of adults diagnosed with diabetes, and percent of stroke deaths. Both unemployment percentage and percent of adults diagnosed with diabetes have a positive effect on fatality rates while the percent of stroke deaths has negative effect, which is odd as we would expect to have an increased effect on fatality rates as percent of stroke deaths increases.

Other than the predictor variable for percent of adults diagnosed with diabetes having a VIF value larger than five, all other VIF values are less than five suggesting that there is minimal multicollinearity. However, this is the first model to show signs of multicollinearity, which means that we should look to not validate this model as our preferred as the multicollinearity present could reduce the precision of the predictor variables and that we might not be able to have high confidence in the p-values for each variable and its statistical significance. The Anova test for Model Two versus Model Three calculates a p-value less than 0.05, which would designate Model Three is a better fit model than Model Two. 

## Comparing Models
Comparing the three models above, we have chosen to emphasize Model Two. First, Model Two includes more explanatory features than the Limited Model and Model Two has proven to be a better fit than the Limited Model via the Anova test we ran. Model Three does appear to be statistically a better fit than Model Two; however, we have concerns about causality and the presence of multicollinearity. Additionally, the large negative coefficient for the percent of stroke deaths predictor variable in Model Three is worrying. Therefore, we have chosen Model Two as our preferred model.


<!-- Although the models have different emphases, each one must still be a reasonable choice given your modeling goals.  The idea is to choose models that encircle the space of reasonable modeling choices, and to give an overall understanding of how these choices impact results. -->

# Regression Table, Interpreting Model Coefficients, and Practical Significance

<!-- You should display all of your model specifications in a regression table, using a package like [`stargazer`](https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf) to format your output. It should be easy for the reader to find the coefficients that represent key effects at the top of the regression table, and scan horizontally to see how they change from specification to specification. Make sure that you display the most appropriate standard errors in your table, along with significance stars.

In your text, comment on both *statistical significance and practical significance*. You may want to include statistical tests besides the standard t-tests for regression coefficients. -->

TODO: run packages on data
TODO: comment on statistical and practical significance

```{r get robust ses }
rse <- function(model) { 
  sqrt(diag(vcovHC(model)))
  }
```

```{r}
stargazer(
  model_limited, model_two, model_three, 
  se = list(rse(model_limited), rse(model_two), rse(model_three)),
  type = 'text')
```

for every 1% increase in stroke death rate, we expect from our model to see a 44% decrease in fatality rate. (seems weird but the stroke death rate is a *super* small number)

coeffs of model 2

In the limited model, we can see that the mask_ratio variable is statistically significant due to its low p value <0.01, none of the other variables used in the limited model showed any statistical significance.  With regards to practical significance, the value of .006 would be considered to have a very high practical significance in relation to the fatality rate.

In the second model, stroke death, chronic respiratory disease death, unemployment percentage as well as the intercept are shown to have statistical significance.  The chronic respiratory disease death variable is shown to have a high statistical significance in particular.  Considering practical significance, stroke death has high practical significance which could cause large effects on fatality rate if it is prevalent within a state.  Chronic respiratory disease death, while more statistically significant actually poses a smaller effect as deaths due to these pre-existing conditions are calculated on the same plane.  Lastly, the unemployment also shows high practical significance in its effects on the fatality rate when applied to the model.

In the third model, stroke death, poverty and household income are considered slightly statistically significant with one out of three showing higher significance.  Comparing with model two, stroke death now has less statistical significance as well as practical significance when it comes to its ability to affect the fatality rate in the third model.  Interestingly, poverty percent, which did not have statistical significance in the second model now shows a much larger significance going from a p value of 0.66 to 0.01 in the third model.  It also shows a much higher practical significance in relation to the third model compared to the second and will have a greater effect on the fatality rate.  Lastly, the household income which has the highest statistical significance, with a coefficient of 6.1519e-07 is also practically significant with relation to fatality rates.

How Models 1 and 3 differed from Model 2. How it impacted our interpretations?


# Limitations on Model

<!-- As a team, evaluate all of the CLM assumptions that must hold for your model. However, do not report an exhaustive examination all 5 CLM assumption. Instead, bring forward only those assumptions that you think pose significant problems for your analysis. For each problem that you identify, describe the statistical consequences. If you are able to identify any strategies to mitigate the consequences, explain these strategies. 

Note that you may need to change your model specifications in response to violations of the CLM. 

TODO: CLM Assumptions and reasoning for violations
  TODO: how those violations should change our model specifications
TODO: strategies to mitigate violations

TODO: causality concerns / collinearity
  - check plots of var v. var
  - correlation matrix
  - draw causal theories?

- IID -->

We assess the five classical linear model (CLM) assumptions and the violations of the one-equation structural model for our Model 2. This causal analysis relies on the CLM because our dataset consists of only 48 observations, one for each state in the contiguous U.S. Because of this, an accurate interpretation of our results requires analyzing the CLM assumptions: independent and identically distributed random variables, linear conditional expectation, no perfect collinearity, homoskedastic errors, and normally distributed errors. Additionally, we assess if our causal analysis violates any assumptions of the one-equation structural model, including omitted variables, reverse causality, and causal relationships between explanatory variables.

Our model met the CLM assumptions surprisingly well. *Need help assessing IID* We observed that our model tends to slightly underpredict states with particularly low or high fatality rates and overpredict states with mid-range fatality rates. Our residuals versus predictions plot was not exactly linear around zero, which implies our linear model may not be the best fit. However, applying additional logarithmic transformations did not significantly improve the residuals, so we left our model with only % Minority having a log transformation. We proceed with caution when interpreting the model coefficients. A nonlinear model may have fit the data better, but this is out of scope for our work. 

We believe there are several concerns with our model and the assumptions of the one-equation structural model. First, there could plausibly exist some reverse causality in our model, particularly with the policy variables. For example, our model currently assumes that longer mask mandates will cause an impact on COVID-19 fatality rates. However, it is also reasonable to say that high COVID-19 fatality rates will cause mask mandates to last longer. The latter causality statement is likely stronger than the first, which is why our coefficient on Mask Ratio is positive. The coefficient on this feature, therefore, explains the correlation between Mask Ratio and Fatality rate but not the causality. Second, it is also plausible that causal relationships exist between our explanatory variables. This is likely most prevalent among our health features. We tried to account for this by limiting the number of health variables we use. For instance, we omitted % of Adults with Obesity but left % of Adults with Diabetes in our model because obesity is a direct cause of diabetes. However, it is likely that we did not catch all of these relationships, which causes some causal concerns with our health features. Finally, omitted variable bias is another concern, which is discussed further in the next section.

- Linear conditional expectation
###> To assess whether there is a linear conditional expectation, we've learned to look at the predicted vs. residuals of the model.
```{r}
df %>% 
  mutate(
    model_two_preds = predict(model_two), 
    model_two_resids = resid(model_two)
  ) %>% 
  ggplot(aes(model_two_preds, model_two_resids)) + 
  geom_point() + 
  stat_smooth()
```
Our comments
- edge effects not lookin too good

###> This doesn't look good. There seems to be a pretty clear non-linear relationship in this data -- perhaps parabolic or logarithmic.
###> To correct this, we will try variable transformations, hoping to end up with a more linear pattern in this plot.
### > Additionally, you may sometimes want to create predictor versus fitted plots, which may give you clues about what variables you need to transform.
```{r}
# vars_2_reduced <- subset(df_figs, select = c('Mask Ratio', "% Adults with Diabetes", '% Unemployed', 'Home Ratio', '% Deaths from Chronic
# Resp Disease', '% Minority'))

df <- df %>% 
  mutate(
    model_two_preds = predict(model_two), 
    model_two_resids = resid(model_two)
  ) 
mask_resids <- df %>% 
  ggplot(aes(mask_ratio, model_two_resids)) + 
  geom_point() + 
  stat_smooth()
diabetes_resids <- df %>% 
  ggplot(aes(Diabetes_Diagnosed_Perc, model_two_resids)) + 
  geom_point() + 
  stat_smooth()
unemployment_resids <- df %>% 
  ggplot(aes(Unemployment_Perc, model_two_resids)) + 
  geom_point() + 
  stat_smooth()
home_resids <- df %>% 
  ggplot(aes(home_ratio, model_two_resids)) + 
  geom_point() + 
  stat_smooth()
resp_resids <- df %>% 
  ggplot(aes(Chronic_Respiratory_Disease_Death_Perc, model_two_resids)) + 
  geom_point() + 
  stat_smooth()
minority_resids <- df %>% 
  ggplot(aes(Minority_Percentage, model_two_resids)) + 
  geom_point() + 
  stat_smooth()
```

```{r}
mask_resids
diabetes_resids
unemployment_resids
home_resids
resp_resids
minority_resids
```
- looks a bit worse, edge effects still


- No perfect collinearity
### > First, we can look at our coefficients, and notice that R has not dropped any variables.
```{r}
model_two$coefficients
```
- no perfect collinearity

```{r, message = FALSE}
df %>% 
  select(
    Fatality_Rate, mask_ratio, Diabetes_Diagnosed_Perc, Poverty_Perc, home_ratio, Chronic_Respiratory_Disease_Death_Perc, Minority_Percentage, model_two_resids
  ) %>%
  GGally::ggpairs()
```


### > This tells us that there is no perfect collinearity.  This assumption also includes the requirement that a BLP exists, which may not happen if there are heavy tails.  In this case, though, we don't see any distributions that look like they have unusually low or high values.
- Homoskedastic errors
### > To assess whether the distribution of the errors is homoskedastic, we can examine the residuals versus fitted plot again.  We are interested in whether there is a band of even thickness from left to right. Looking at the plot above, indeed, it does look like there might be some increase in the variance of the residuals at the upper side of the predicted values, but it is not severe.  We may hope that a log transform fixes this small problem
### > Another idea is to examine the scale-location plot.  Homoskedasticity would show up on this plot as a flat smoothing curve.
 
```{r}
plot(model_two, which=3)
```
- homoskskskedasticity actually not lookin too bad --> model_two looking 10/10!!!

### > This plot looks quite good, suggesting no major problem with heteroskedasticity.
- Normally distributed errors
```{r}
plot_one <- df %>% 
  ggplot(aes(x = model_two_resids)) + 
  geom_histogram()
  
plot_two <- df %>% 
  ggplot(aes(sample = model_two_resids)) + 
  stat_qq() + stat_qq_line()
plot_one / plot_two
```
- not too bad!! some minor deviation from normality towards the tails
- high frequency of values just below -0.005

> The histogram of residuals and the qqplot shows some some deviation from normality, specifically a right skew and perhaps an unusual concentration on the right tail.
>
> This is not a problem for unbiasedness, and it is not a problem for our standard errors.  However, this will threaten the validity of our t-tests and confidence intervals.  We may hope to fix this problem with a variable transformatin.


### 5. Discussion of Omitted Variables -- All, led by Spencer Song

If the team has taken up an explanatory (i.e. causal) question to evaluate, then identify what you think are the 5 most important *omitted variables* that bias results you care about. For each variable, you should *reason about the direction of bias* caused by omitting this variable. If you can argue whether the bias is large or small, that is even better. State whether you have any variables available that may proxy (even imperfectly) for the omitted variable. Pay particular attention to whether each omitted variable bias is *towards zero or away from zero*. You will use this information to judge whether the effects you find are likely to be real, or whether they might be entirely an artifact of omitted variable bias.
Vaccine distribution

We want to apply OVB concepts to our second regression model. We have determined the following as our 5 most important omitted variables:

| Regression                                     | Omitted Variable                |
|------------------------------------------------|---------------------------------|
| $Fatality Rate = \beta_0 + \beta_1 attendance + u$     | $extremity\_of\_weather$                |
| $lifespan = \beta_0 + \beta_1 cigarettes + u$  | $exercise$                      |
| $lifespan = \beta_0 + \beta_1 cigarettes + u$  | $time\_socializing$             |
| $wage = \beta_0 + \beta_1 grad\_education + u$ | $experience$                    |
| $wage = \beta_0 + \beta_1 grad\_education + u$ | desire to effect $social\_good$ |

1. Diets and quality of food distribution (tied to distribution of healthy restaurants)
Aggregated health of food availability throughout a state would likely be negatively correlated with COVID19 fatality cases. Overall, a healthier population will likely be more adverse to higher fatality rates and severe reactions to COVID19.

3*. Weather
One could make the argument that extreme temperature swings and humidity will be positively correlated with fatality rates. 
<!-- It is well known that extreme temperature changeswill weaken a person's immune system and their body's ability to fight a virus. This would imply that states with less moderate weather will have higher fatality rates with COVID. A similar omitted variable that relates could be the humidity of the air-- as we know, virus' spread when there are lower humidity rates.  -->
This bias could be relatively large given the lower percentage of fatality rates in the first place. 

6*. Political party ideology on COVID 19 and the distribution of their ideas

% (of registered voters that are?) Republican --> different policies implemented?? different messaging about covid from leaders? --> impacts fatality rates

I believe that political ideology (Positive opinions on the media reporting of COVID severity) will have a negative? correlation with fatality rates. The bias of this would likely be smaller, but the at-risk population that believes in COVID's severity will likely take more drastic measures to protect themselves.

7*. Tourist Hotspots / travel patterns / travel zones: 
I believe that distances from tourist hotspots / urban zones will likely have a negative correlation with fatality rates. A further distance that cities are from unpredictable and unwanted influxes of tourists would likely correlate with lower fatality rates.

8. Informational resources on COVID 19 / Misspreading of information about COVID across states:
opinion on covid severity

### 6. Conclusion -- save 4 later

Make sure that you end your report with a discussion that distills key insights from your estimates and addresses your research question.

TODO: all

## Rubric for Evaluation

You may use the following, loosely structured rubric to guide your writing.

- **Introduction.** Is the introduction clear? Is the research question specific and well defined? Does the introduction motivate a specific concept to be measured and explain how it will be operationalized. Does it do a good job of preparing the reader to understand the model specifications?

- **The Initial Data Loading and Cleaning.** Did the team notice any anomalous values? Is there a sufficient justification for any data points that are removed? Did the report note any coding features that affect the meaning of variables (e.g. top-coding or bottom-coding)? Overall, does the report demonstrate a thorough understanding of the data? Does the report convey this understand to its reader -- can the reader, through reading this report, come to the same understanding that the team has come to? 

- **The Model Building Process.** Overall, is each step in the model building process supported by EDA? Is the outcome variable appropriate? Did the team clearly state why they chose these explanatory variables, does this explanation make sense in term of their research question? Did the team consider available variable transformations and select them with an eye towards model plausibility and interpretability? Are transformations used to expose linear relationships in scatterplots? Is there enough explanation in the text to understand the meaning of each visualization?

- **Regression Models:**
   - **Base Model.** Does this model only include key explanatory variables? Do the variables make sense given the measurement goals? Did the team apply reasonable transformations to these variables, to capture the nature of the relationships? Does the team write about this model in prose in a way that is appropriate? 
   - **Second Model.** Does this model represent a balanced approach, including variables that advance modeling goals without causing major issues? Does the model succeed in reducing standard errors of the key variables compared to the base model? Does it capture major non-linearities in the joint distribution of the variables? Does the team write about this model in prose in a way that is appropriate? 
   - **Third Model.** Does this model represent a maximalist approach, erring on the side of including most variables? Is it still a reasonable model? Are there any variables that are outcomes, and should therefore still be excluded? Is there too much colinearity, to the point that the key causal effects cannot be measured? Does this team write about this model in prose in a way that is appropriate? 

- **A Regression Table.** Are the model specifications properly chosen to outline the boundary of reasonable choices? Is it easy to find key coefficients in the regression table? Does the text include a discussion of practical significance for key effects? 
   
- **Plots, Figures, and Tables** Do the plots, figures and tables that the team has chosen to include successfully move forward the argument that they are making? Has the team chosen the most effective method (a table or a chart) to display their evidence? Is that table or chart the most communicative it could be? Is every plot, figure, and table that is included in the report referenced in the narrative argument?

- **Assessment of the CLM.** Has the team presented a sober assessment of the CLM assumptions that might be problematic for their model? Have they presented their analysis about the consequences of these problems (including random sampling) for the models they estimate? Did they use visual tools or statistical tests, as appropriate? Did they respond appropriately to any violations?

- **An Omitted Variables Discussion.** Did the report miss any important sources of omitted variable bias? Are the estimated directions of bias correct? Was their explanation clear? Is the discussion connected to whether the key effects are real or whether they may be solely an artifact of omitted variable bias?

- **Conclusion.** Does the conclusion address the research question? Does it raise interesting points beyond numerical estimates? Does it place relevant context around the results?

- Are there any other errors, faulty logic, unclear or unpersuasive writing, or other elements that leave you less convinced by the conclusions?
